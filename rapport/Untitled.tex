%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% LaTeX Template
% Version 1.0 (26/01/16)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[11pt, letterpaper]{article}
\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[frenchb]{babel}
\usepackage[top=3cm, bottom=3cm, left=2cm, right=2cm]{geometry}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{amsmath}
\usepackage{tabularx}
\usepackage{float}
\usepackage[linesnumbered, ruled]{algorithm2e}
\usepackage{url}
\usepackage{relsize}

\newcommand{\hmark}{\rule{\linewidth}{0.5mm}}

\begin{document}
\begin{titlepage}
\pagenumbering{gobble}

\centering

\begin{figure}[t]
\begin{center}
\includegraphics[width=8cm]{Images/upmc.png}
\end{center}
\end{figure}

\hmark \\[0.5cm]
\textsc{\textbf{\Large R\'{e}solution de probl\`{e}mes, g\'{e}n\'{e}ration de mots-crois\'{e}s}} \\[0.5cm]
\textsc{Androide M1 -- RP} \\[0.5cm]
\hmark \\[5cm]

\begin{minipage}{0.4\textwidth}
\begin{flushleft}
Thibault \textsc{Gigant} \\
Laura \textsc{Greige}
\end{flushleft}
\end{minipage}
~
\begin{minipage}{0.4\textwidth}
\begin{flushright}
\emph{Enseignants :}\\[0.5cm]
Patrice \textsc{Perny} \\
Morgan \textsc{Chopin}
\end{flushright}
\end{minipage}\\[4cm]

\large 2015 -- 2016

\end{titlepage}
\newpage

\tableofcontents

\newpage

\pagenumbering{arabic}

\pagestyle{fancy}
\renewcommand{\headrulewidth}{1pt}
\lhead{\textbf{RP -- R\'{e}solution de probl\`{e}mes, g\'{e}n\'{e}ration de mots-crois\'{e}s}}
\rhead{}

\section*{Introduction}
\addcontentsline{toc}{section}{Introduction}

Dans ce projet, on s'int\'{e}resse \`{a} compl\'{e}ter une grille de taille $M\times N$. Dans un premier temps, on mod\'{e}lisera ce probl\`{e}me comme un probl\`{e}me de satisfaction de contraintes et on d\'{e}veloppera plusieurs m\'{e}thodes diff\'{e}rentes de recherche d'une solution au probl\`{e}me CSP : arc consistance du graphes des contraintes ($AC3$), retour arrière chronologique ($RAC$) avec forward checking ($FC$), et conflict back-jumping ($CBJ$) avec $FC$ lui aussi aussi. La grille peut \^{e}tre d\'{e}j\`{a} partiellement remplie par l'utilisateur.

Dans un second temps, on mod\'{e}lisera ce probl\`{e}me comme un CSP valu\'{e}. Chaque mot du dictionnaire sera muni d'un poids positif ou nul appartenant à $\left[0,1\right]$ et on d\'{e}veloppera un algorithme de type Branch and Bound qui permette de rechercher la solution optimale qui serait la solution de poids maximal dans la grille.

\section{Mod\'{e}lisation par un CSP et r\'{e}solution}

\subsection{Mod\'{e}lisation}

Pour r\'{e}soudre ce probl\`{e}me, on peut le mod\'{e}liser comme un probl\`{e}me de satisfaction de contraintes en associant une variable \`{a} chaque mot de la grille. Supposons qu'il y ait $m$ mots dans la grille. \bigskip

\begin{description}
	\item[Variables :] ~ $x_{i}~,~\forall i \in \{1,...,m\}$
	
	\bigskip
	
	\item[Domaines :] Soit $dict$ un dictionnaire de mots admissibles:
	\begin{align*}
	D(x_{i}) =dict
	\end{align*}
	
	\item[Contraintes :]\hspace{0.1cm}\\
	\begin{itemize}
		\item Soit $l_{i}$ la taille du mot en $i$ et $len$ une fonction renvoyant le nombre de lettres d'une variable :
		
		\begin{equation} 
		len(x_{i}) = l_{i}
		\label{contrainte1}
		\end{equation}
		
		\item Pour tous mots $x_{i}$ et $x_{j}$ qui se croisent \`{a} la \textit{q}-i\`{e}me lettre de $x_{i}$ et \`{a} la \textit{p}-i\`{e}me lettre de $x_{j}$, on a:
		\begin{equation} 
		x_{i}[q] = x_{j}[p]
		\label{contrainte2}
		\end{equation}
		
		\item Si l'on ajoute la contrainte suppl\'{e}mentaire qu'un m\^{e}me mot ne peut appara\^{i}tre plus d'une fois dans la grille, il suffit d'ajouter la contrainte \textit{AllDiff}:
		\begin{equation} 
		\textit{AllDiff}~(x_{1},x_{2},...x_{m})
		\label{contrainte3}
		\end{equation}
	\end{itemize}
\end{description}

\subsection{Implémentation}
Tout cela doit être implémentée de la manière la plus simple possible en machine. Voici le détail de ce qui a été effectué pour ce projet.

\subsubsection{Les domaines des variables}
\label{domaines}
Pour récupérer les domaines des variables, une fonction qui lit un fichier contenant une liste de mots a été créé. Cette fonction lit chaque mot du fichier et le stocke dans un dictionnaire \texttt{Python} dont les clés sont la taille des mots contenus. De plus, les caractères non-ascii ont été transformés en ascii ou simplement supprimé par une fonction issue d'une bibliothèque externe. Ce choix a été fait pour éviter que des mots compatibles mais qui se croisent en \og é \fg{} et \og e \fg{} soient reconnus comme en conflit.

En revanche, les mots ne sont pas stockés sous la forme d'une simple liste. En effet, chaque domaine de mots d'une certaine longueur est représenté par une structure arborescente contenant tous les mots de cette taille. Chaque noeud contient un caractère. Ainsi, un chemin entre la racine et une feuille représente un mot. Les feuilles sont signifiées par une chaîne vide, signalant une fin de mot. La figure suivante montre un arbre contenant quatre mots de longueur 3 :
\begin{figure}[!h]
	\begin{center}
		\includegraphics[scale=0.8]{Images/arbre.png}
		\caption{Représentation arborescente d'un domaine}
	\end{center}
\end{figure}

De cette manière, il est alors beaucoup plus rapide d'effectuer des tests de consistance. Effectivement, si on souhaite par exemple fixer la première lettre au caractère \og $c$ \fg{} il ne suffit alors plus que de retirer tous les noeuds descendant de la racine dont la donnée n'est pas un \og $c$ \fg{}. En une itération, avec l'exemple précédent, on retirerait alors 3 mots en une seule itération. On peut alors faire de même si l'on veut fixer la deuxième lettre. Il suffit, pour chaque noeud sous la racine, de retirer ses fils qui n'ont pas la lettre voulue. Et ainsi de suite\dots

Dans le pire des cas, on veut fixer la dernière lettre, et on devra parcourir tout l'arbre. En pratique, il est certain que le temps gagné en retirant les branches situées en haut de l'arbre compense largement ce problème.

Il faut aussi noter que pour des dictionnaires de petite taille, la probabilité d'avoir des mots assez similaires, et donc un arbre plus restreint, est assez faible. Cependant, sur les petits dictionnaires, les algorithmes se résolvent très rapidement, car les domaines des variables sont eux aussi petits. Sur ceux de grande taille, la probabilité d'avoir des mots plutôt similaires est beaucoup plus élevée. Cette représentation accélèrera donc grandement l'exécution des algorithmes, qui lorsqu'il s'agira de ne garder que les mots ayant une lettre précise à une position précise, pourront ne garder qu'une branche à tous les niveaux concernés.

Pour chaque variable, on donnera alors comme domaine l'arbre du dictionnaire récupéré correspondant à sa taille. En lui donnant un arbre contenant uniquement les mots de sa taille, on effectue déjà la satisfaction de la contrainte (\ref{contrainte1}) est déjà vérifiée. Il n'y aura plus que les deux autres contraintes à satisfaire.

\subsubsection{Algorithme d'arc consistance $AC3$ }
Grâce à la représentation des domaines explicitée dans la sous-section précédente (\ref{domaines}), cet algorithme est réellement simple à appliquer. L'algorithme du cours a été appliqué, avec une légère modification : lorsqu'on regarde un couple de variables liées par une contrainte binaire, les deux domaines sont modifiés à la même itération. Voici l'algorithme appliqué:

\begin{algorithm}[H]
	\caption{Procédure $AC3$}
	\Entree{
		\par\leftskip=1.5em Variables $x_i, \forall i \in {1, \dots, m}$
	}
	
	\bigskip
	\Deb{
		$file$ := creerFile()
		
		\Pour{$(x_i, x_j), i < j$ liées par une contrainte}
		{
			enfiler($(x_i, x_j)$)
		}
		
		\medskip
		\Tq{estNonVide(file)}
		{
			$(x_i, x_j)$ := defiler($file$)
			
			change1, change2 = REVISE($x_i$, $x_j$)
			
			\Si{change1}
			{
				\Pour{$(x_k, x_i), k < i$ liées par une contrainte}
				{
					enfiler($(x_k, x_i)$)
				}
				
				\Pour{$(x_i, x_k), i < k$ liées par une contrainte}
				{
					enfiler($(x_i, x_k)$)
				}
			}
			
			\Si{change2}
			{
				\Pour{$(x_k, x_j), k < j$ liées par une contrainte}
				{
					enfiler($(x_k, x_j)$)
				}
				
				\Pour{$(x_j, x_k), j < k$ liées par une contrainte}
				{
					enfiler($(x_j, x_k)$)
				}
			}
		}
	}
	
\end{algorithm}

Avec la procédure REVISE suivante :\\

\begin{algorithm}[H]
	\caption{Procédure REVISE}
	\Entree{
		\par\leftskip=1.5em Variables $x_i$ et $x_j$ liées par une contrainte
	}
	
	\bigskip
	\Deb{
		$i$ := indice de la lettre soumise à la contrainte de la variable $x_i$
		
		$j$ := indice de la lettre soumise à la contrainte de la variable $x_j$
		
		$lettres_i$ := ensemble de lettres en position $i$ de $x_i$
		
		$lettres_j$ := ensemble de lettres en position $j$ de $x_j$
		
		$intersection$ := intersection des ensembles $lettres_i$ et $lettres_j$
		
		mofications := [False, False]
		
		\Si{$lettre_i \neq intersection$}
		{
			Retirer de l'arbre domaine de $x_i$ toutes les lettres au niveau $i$ qui ne sont pas dans $intersection$
			modifications[0] := True
		} 
		
		\Si{$lettre_j \neq intersection$}
		{
			Retirer de l'arbre domaine de $x_j$ toutes les lettres au niveau $j$ qui ne sont pas dans $intersection$
			modifications[1] := True
		}
		
		\Retour{modifications} 
		
	}
\end{algorithm}

\bigskip

En procédant comme cela, on ne calcule pour chaque couple de variable qu'une seule fois les lettres communes et leur intersection, en modifiant les domaines des deux variables. En suivant à la lettre l'algorithme du cours, on aurait été obligé de calculer ces données une fois pour $(x_i, x_j)$ et une fois pour $(x_j, x_i)$. On améliore ainsi de beaucoup la vitesse de calcul.

\subsubsection{Heuristiques}
Plusieurs heuristiques permettant de choisir le prochain mot à instancier ont été testées :
\begin{description}
	\item[heuristic\_next :] Cette heuristique renvoie simplement la prochaine parmi celles qui ne sont pas encore instanciées.
	\item[heuristic\_max\_constraints :] Cette heuristique renvoie le mot qui possède le plus de contraintes binaires.
	\item[heuristic\_min\_domain :] Cette heuristique renvoie le mot qui possède le plus petit domaine.
	\item[heuristic\_constraints\_and\_size :] Cette heuristique renvoie le mot qui possède le plus de contraintes binaires, et en cas d'égalité celui d'entre eux qui a le plus petit domaine.
	\item[heuristic\_size\_and\_constraints :] Cette heuristique renvoie le mot qui possède le plus petit domaine, et en cas d'égalité celui d'entre eux qui a le plus de contraintes binaires.
	\item[heuristic\_max\_constraints\_with\_instanciated :] Cette heuristique renvoie le mot qui possède le plus de contraintes binaires avec les mots déjà instanciés, et en cas d'égalité celui d'entre eux qui a le plus petit domaine.
\end{description}

Dans tous les cas (hormis heuristic\_next qui n'en a pas besoin), en cas d'égalité à la fin des calculs, une variable correspondant au critère est choisie au hasard. De cette manière, deux lancements sur la même grille avec le même dictionnaire pourront donner des résultats différents.

\subsubsection{Algorithme du Retour Arrière Chronologique avec Forward Checking}
\label{RAC}
Pour cet algorithme, le modèle du cours a été encore une fois appliqué avec une légère variation. Après avoir instancié un mot et lancé l'algorithme de Forward Checking, et avant de lancer l'appel récursivement avec les variables qui restent à instancier, on vérifie que lors du Forward Checking on n'a pas vidé complètement le domaine d'une variable qui était liée par une contrainte binaire. Dans ce cas, l'instanciation courante ne pourra pas donner de résultat satisfaisant, et il est inutile de faire l'appel récursif. Il faut alors rétablir les domaines qui ont été modifiés, comme si l'appel récursif avait échoué.

De plus, l'avantage de cette méthode, mise à part l'accélération évidente de la vitesse de calcul d'une solution, est qu'elle permet de diminuer l'avantage que comporte le fait d'utiliser l'heuristique renvoyant la variable avec le plus petit domaine. En effet, sans ce changement, lors d'un Forward Checking vidant complètement le domaine d'une variable liée, l'heuristique des plus petits domaines renverra systématiquement la variable dont le domaine a été vidé, et cet appel récursif échouera, et le retour arrière sera immédiat. Avec une autre heuristique, il est possible qu'un autre mot, au pire avec un domaine immense, soit choisi. On ne saura alors que bien plus tard que c'est à ce niveau là qu'il fallait revenir.

Nous sommes conscient que cet ajout rend moins avantageux l'algorithme de Conflict BackJumping qui ne remarquera ce le conflit qu'une fois arrivé à la variable. Certes, $CBJ$ retournerait plus vite à l'itération conflictuelle que le $RAC$ sans cet ajout, mais il peut quand même perdre du temps à aller vérifier des variables avec un domaine potentiellement grand, avant d'arriver à celle qui comportait un conflit.

\subsubsection{Conflict BackJumping}
Cette fois, l'algorithme du cours a été appliqué à la lettre. Notons toutefois que le Forward Checking a lui aussi été appliqué à chaque instanciation de variable. Ceci a rendu la recherche d'un conflit local inutile. En effet, il y a conflit local seulement si une instanciation de cette variable est incompatible avec l'instanciation d'une variable précédente. Cela ne peut arriver, puisqu'on a préalablement vidé le domaine de la variable courante des potentiels conflits par Forward Checking.

Il est d'ailleurs intéressant de noter, comme le montrent les résultats de la section suivante, que le $CBJ$ donne une solution moins rapidement que $RAC$. La raison pour cela a été donnée dans le dernier paragraphe de la section précédente (\ref{RAC}).

Pour ces deux derniers algorithmes, il a été implémentée une fonctionnalité permettant de choisir si l'on souhaite que les mots n'apparaissent qu'une seule fois dans la grille. Cette particularité est vérifiée au niveau du Forward Checking, qui supprime du domaine des variables de même taille le mot qui vient d'être instancié. Par la suite, cette fonctionnalité sera toujours appliquée. En effet, souvent une solution plus rapide sera donnée car les grilles sont assez symétriques et permettent de positionner les mots de telle sorte qu'ils forment des structures elles aussi symétriques, comme sur la figure suivante :

\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.9]{Images/gridA_not_uniq.png}
		\caption{Grille A résolue sans la contrainte (3)}
	\end{center}
\end{figure}

\subsection{Exp\'{e}rimentation}
Les algorithmes ont été appliqués aux grilles données dans le sujet, ainsi qu'à quelques autres grilles récupérées du site \url{http://puzzles.about.com/od/howtostutorials/ig/CrosswordGrids/}, et à quelques instances générées aléatoirement. Les résultats sont stockés dans le dossier du projet :\\
\texttt{Crosswords/Data/Results/Grilles\_Resolues/}\\
et leurs images correspondantes en annexe de ce rapport.

\subsubsection*{Application}

Dans cette section, nous allons tester les performances de nos algorithmes, d'abord en utilisant RAC. Les graphes suivants représentent le temps d'exécution des la grilles A et B (grilles de respectivement 5 et 7 cases de côté du sujet), en fonction de l'heuristique appliquée, avec et sans exécution de AC3 :

\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.3]{Images/gridA_ac3.png}
		\caption{Temps d'exécution de la grille A avec et sans AC3}
	\end{center}
\end{figure}

\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.3]{Images/gridB_ac3.png}
		\caption{Temps d'exécution de la grille B avec et sans AC3}
	\end{center}
\end{figure}

On remarque que sans AC3, les temps d'exécution sont globalement plus élevés, quelle que soit l'heuristique employée. Avec AC3, les domaines ont été écrémés et il y a donc moins de possibilités à passer en revue. Les points où AC3 est en-dessous sont probablement dû aux aléas des heuristiques qui peuvent donner des instances plus compliquées aux instances lancées après AC3 qu'aux autres. Nous avons tenté de diminuer l'effet de cet aléa en lançant l'algorithme 5 fois, le point affiché étant une moyenne des temps d'exécution de ces 5 lancers. Malheureusement cela n'a pas suffit. Quoi qu'il en soit, dans la suite, on appliquera donc AC3 avant chaque lancement.

De même, sur le graphe suivant, on remarque que l'heuristique renvoyant simplement le mot suivant dans la liste des variables non-instanciées est de loin le plus long. L'échelle des temps d'exécution a même dû être passée en logarithmique pour ne pas effacer les différences sur les heuristiques suivantes. Cela s'explique d'autant plus que les variables lors de leur création sont placées de telle sorte que les mots horizontaux se situent au début de la liste, et les mots verticaux à la fin de la liste. Ainsi, avant de déterminer qu'une instanciation d'un mot vertical n'est pas correcte, il faut attendre que tous les mots horizontaux soient placés, et le nombre de conflits est alors élevé.

\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.4]{Images/gridA_heuristics.png}
		\caption{Temps d'exécution de la grille A en fonction de l'heuristique utilisée}
	\end{center}
\end{figure}

En revanche, on observe que les heuristiques donnant un temps minimal sont celles qui prennent en compte la taille des domaines en premier. De plus, si on ajoute le fait de prendre les variables ayant le plus de contraintes binaires après ceci, on diminue encore légèrement le temps d'exécution. Pour la suite, nous utiliserons donc cette heuristique : \emph{heuristic\_size\_and\_constraints} qui semble la plus rapide quelle que soit la grille d'entrée.

Lorsqu'on regarde le temps d'exécution de l'algorithme $RAC$ en fonction de la taille de la grille (en nombre de cases), on observe la chose suivante :

\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.4]{Images/taille_compare_rac.png}
		\caption{Temps d'exécution des grilles à disposition}
	\end{center}
\end{figure}

Les grilles étant rangées par ordre croissant, on peut s'attendre à ce que la courbe soit strictement croissante. Mais il n'en est rien. Le tableau suivant explique cet état de fait.

\medskip
\noindent
\begin{tabularx}{\textwidth}{|X|X|X|X|}
	\hline
	\textbf{Grille} & \textbf{Nombre de mots} & \textbf{Nombre de contraintes binaires total} & \textbf{Nombre de contraintes / Nombre de mots}\\
	\hline
	randomGrid5x5.txt & 9 & 10 & 1.1111111111111112\\
	\hline
	gridA.txt & 10 & 19 & 1.9\\
	\hline
	gridB.txt & 18 & 33 & 1.8333333333333333\\
	\hline
	gridC.txt & 24 & 52 & 2.1666666666666665\\
	\hline
	randomGrid10x10.txt & 29 & 40 & 1.3793103448275863\\
	\hline
	grid13x13GridIndex.txt & 68 & 124 & 1.8235294117647058\\
	\hline
\end{tabularx}

\medskip
On remarque alors clairement que plus que la taille, c'est bien le ratio entre nombre de variables de la grille et nombre de contraintes binaires qui influe sur le temps d'exécution. Plus ce ratio est élevé, et plus le temps d'exécution est grand.

Maintenant, si l'on s'intéresse à l'influence de la taille du dictionnaire sur le temps d'exécution d'une grille, le graphe suivant, représentant le temps d'exécution de $RAC$ sur la grille C (celle de 9 de côté du sujet) nous donne une bonne indication :

\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.4]{Images/gridC_dicos.png}
		\caption{Temps d'exécution de $RAC$ sur la grille C en fonction du dictionnaire appliqué}
	\end{center}
\end{figure}

On peut noter que le temps d'exécution augmente au début avec la taille du dictionnaire. Mais les deux dernier dictionnaires, assez conséquents de taille approximative 133000 mots et 135000 mots nous donnent tort. Il est probable que ces dictionnaires s'arrangent bien avec la grille. Il faut donc comparer avec une autre grille, que nous donne des résultats plus ou moins similaires :

\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.4]{Images/gridA_dicos.png}
		\caption{Temps d'exécution de $RAC$ sur la grille A en fonction du dictionnaire appliqué}
	\end{center}
\end{figure}

On peut alors supposer qu'à un certain moment, si l'on augmente la taille d'un dictionnaire, le Forward Checking fonctionne plutôt bien et élimine assez vite des pans entiers de possibilités, et on trouve une solution aussi rapidement voire plus vite qu'avec un plus petit dictionnaire. De plus, on peut supposer que de nombreux mots dans les plus grands dictionnaires ne s'appliquent tout simplement pas à grille qu'on résout. Ainsi, en réalité, même si le dictionnaire est plus grand, le nombre de mots dans les domaines est diminué.
Bien entendu, cela est valable si nous ne nous situons pas dans des cas pathollogiques nécessitant de parcourir tout le domaine de chaque variable.

\subsubsection*{Conflict BackJumping}

L'algorithme de Conflict BackJumping est somme toute assez similaire algorithmiquement que le Retour Arrière Chronologique. La seule différence c'est qu'il ne perd pas autant de temps lors d'un retour arrière en remontant directement jusque là où se présente un conflit. Les tendances des courbes précédentes avec les mêmes paramètres seront identiques.

Il faut alors comparer les deux algorithmes : $RAC$ et $CBJ$, ce qui est fait dans le graphe suivant :

\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.4]{Images/compare_algos.png}
		\caption{Temps d'exécution de $RAC$ et $CBJ$ en fonction de la grille lancée}
	\end{center}
\end{figure}

Ce qu'on remarque alors, c'est que les deux algorithmes se suivent de près, à l'exception de quelques points, qui sont probablement dus à des coups de \og chance \fg{} de la part de $RAC$. En effet, comme expliqué dans la section \ref{RAC}, ce résultat était attendu. Avec l'amélioration de $RAC$ qui a été implémentée, les deux algorithmes se ressemblent fortement. On peut même dire que pour les plus grandes instances, l'algorithme $RAC$ tel que nous l'avons modifié est souvent plus rapide que $CBJ$.

\subsubsection*{Applications sur des grilles de tailles plus grandes}

La méthode de Retour Arrière Chronologique accompagnée d'une heuristique qui choisit d'instancier d'abord les mots de plus petit domaine (puis ayant le plus de contraintes binaires) donne des résultats satisfaisants même sur des grandes instances. Elle a donc été appliquée à des instances grandissantes. Malheureusement, le temps de résolution augmentant exponentiellement avec la taille des grilles (du moins le nombre de mots qu'elles comportent), des tailles de grille au-delà de 18 cases de côté avec une densité de cases noires d'approximativement 45\% commence à devenir trop long pour qu'on lance un tel algorithme sur nos machines.


\newpage

\section{Extension au cas pond\'{e}r\'{e}}

\subsection{Mod\'{e}lisation}

Dans cette partie, on suppose que chaque mot du dictionnaire est muni d'un poids réel positif ou nul appartenant à $\left[0,1\right]$ repr\'{e}sentant l'importance qu'un utilisateur attache \`{a} ce mot ou la fr\'{e}quence d'occurence de ce mot dans un texte. Pour trouver la solution optimale du probl\`{e}me, c-\`{a}-d la solution de poids maximum dans la grille, il faut utiliser une m\'{e}thode exacte, comme le \og Branch \& Bound \fg{} qui sera repr\'{e}sent\'{e} par un arbre de recherche binaire.

Chaque sous-probl\`{e}me cr\'{e}\'{e} au cours de l'exploration est d\'{e}sign\'{e} par un n\oe{}ud qui repr\'{e}sente les mots choisis pour chaque variable $x_{i}$ de la grille. Les branches de l'arbre symbolisent le processus de s\'{e}paration, elles repr\'{e}sentent la relation entre les n\oe{}uds (ajout du mot $m_{i} \in D(x_{i}$). Cette m\'{e}thode arborescente nous permettra donc d'\'{e}num\'{e}rer toutes les solutions possibles.

En chacune des feuilles de l'arbre, on a une solution possible qui correspond ou non \`{a} une solution admissible et on retient la meilleure solution obtenue, qui dans ce cas, sera la solution étant poids maximum.\\

Pour am\'{e}liorer la complexit\'{e} du \og Branch \& Bound \fg, seules les solutions qui v\'{e}rifient les contraintes de consistances potentiellement de bonne qualit\'{e} seront \'{e}num\'{e}r\'{e}es, les solutions ne pouvant pas conduire \`{a} am\'{e}liorer la solution courante ne sont pas explor\'{e}es. \\

Le \og Branch \& Bound \fg{} est bas\'{e} sur trois principes : le principe de s\'{e}paration, le principe d'\'{e}valuation et le parcours de l'arbre.

\subsubsection{Principe de s\'{e}paration}

Le principe de s\'{e}paration consiste \`{a} diviser le probl\`{e}me en un certain nombre de sous-probl\`{e}mes qui ont chacun leur ensemble de solutions r\'{e}alisables. En r\'{e}solvant tous les sous-probl\`{e}mes et en prenant la meilleure solution trouv\'{e}e, on est assur\'{e} d'avoir r\'{e}solu le probl\`{e}me initial. Ce principe de s\'{e}paration est appliqu\'{e} de mani\`{e}re r\'{e}cursive \`{a} chacun des sous-ensembles tant que celui-ci contient plusieurs solutions. \\
Remarque : La proc\'{e}dure de s\'{e}paration d'un ensemble s'arr\^{e}te lorsqu'une des conditions
suivantes est v\'{e}rifi\'{e}e : \\
-- on sait que l'ensemble ne contient aucune solution admissible (cas o\`{u} les mots ne v\'{e}rifient pas les conditions de consistance) ; \\
-- on conna\^{i}t une solution meilleure que toutes celles de l'ensemble ;

\subsubsection{Principe d'\'{e}valuation}

Le principe d'\'{e}valuation a pour objectif de conna\^{i}tre la qualit\'{e} des n\oe{}uds \`{a} traiter. La m\'{e}thode de \og Branch and Bound \fg{} utilise deux types de bornes : une borne inf\'{e}rieure de la fonction d'utilit\'{e} du probl\`{e}me initial et une borne sup\'{e}rieure de la fonction d'utilit\'{e}. La connaissance d'une borne inf\'{e}rieure du probl\`{e}me et d'une borne sup\'{e}rieure de la fonction d'utilit\'{e} de chaque sous-probl\`{e}me permet d'arr\^{e}ter  l'exploration d'un sous-ensemble de
solutions qui ne sont pas candidats \`{a} l'optimalit\'{e}.\\

Supposons qu'on est \`{a} un noeud de l'arbre et on a une solution partielle $s_{p}$ au probl\`{e}me. Soit $v(s_p)$ la valeur de cette solution partielle, d\'{e}finie comme agr\'{e}gation des poids des mots qui figurent dans $s_{p}$.

\bigskip

\textbf{Borne inf\'{e}rieure} ~ La borne inf\'{e}rieure est d\'{e}finie comme la somme des poids des mots des variables instanci\'{e}es. Elle nous permet d'obtenir la valeur de la solution trouv\'{e}e \`{a} une feuille de l'arbre.

\begin{align*}
b_{inf} = v(s_p)
\end{align*}

Si la borne inf\'{e}rieure \`{a} une feuille de l'arbre (c-\`{a}-d apr\`{e}s avoir instancier les n variables de la grille) est sup\'{e}rieure \`{a} la valeur de la solution courante, on a trouv\'{e} une meilleure solution.

\bigskip

\textbf{Borne sup\'{e}rieure} ~ Pour \'{e}valuer la qualit\'{e} de ce noeud, nous avons d\'{e}fini la borne sup\'{e}rieure par la somme de la valeur de la solution partielle et du poids maximum des mots de chaque variable $x_i$ non encore instanc\'{e}e dans la grille.

\begin{align*}
b_{sup} = v(s_p) + \sum_{x_i } \max_{m_{j} \in D(x_{i})} p(m_{j})
\end{align*}

En effet, dans le meilleure des cas, la solution optimale est form\'{e}e de mots dont le poids est maximum dans le domaine de chaque variable de la grille, donc on obtient bien une borne sup\'{e}rieure \`{a} chaque sous-probl\`{e}me repr\'{e}sent\'{e} par les n\oe uds de l'arbre. Si cette borne sup\'{e}rieure est inf\'{e}rieure \`{a} la solution courante, il est inutile de continuer \`{a} explorer ce n\oe ud, puisque cette solution partielle ne pourrait pas conduire \`{a} am\'{e}liorer la solution courante.

\subsubsection{Parcours de l'arbre}

Le type de parcours de l'arbre permet de choisir le prochain n\oe{}ud \`{a} s\'{e}parer parmi l'ensemble des n\oe{}uds de l'arborescence. L'exploration en profondeur privil\'{e}gie les sous-probl\`{e}mes obtenus par le plus grand nombre de s\'{e}parations appliqu\'{e}es au probl\`{e}me de d\'{e}part, c'est-\`{a}-dire aux sommets les plus \'{e}loign\'{e}s de la racine (= de profondeur la plus \'{e}lev\'{e}e). L'obtention rapide d'une solution admissible en est l'avantage.

\subsection{Impl\'{e}mentation}

Pour l'impl\'{e}mentation du \og Branch \& Bound \fg{}, nous avons d'abord tri\'{e} les mots du domaine de chaque variable selon leur poids par ordre d\'{e}croissant. Ceci nous permet d'affecter d'abord les mots auxquels on attache plus d'importance, ou sont plus fr\'{e}quent dans un texte aux variables de la grille.

\subsection{Exp\'{e}rimentation}

\subsubsection*{En fonction de la taille du dictionnaire}

Afin de construire un graphe montrant l'\'{e}volution du temps en fonction de la taille du dictionnaire, nous avons g\'{e}n\'{e}r\'{e} 10 instances de dictionnaires contenant chacun 52, 300, 400, 500, 650 et 850 mots pour une grille de taille $5 \times 5$. Nous avons aussi comparer les courbes lorsque les mots dans les grilles sont uniques ou pas.\\

\begin{figure}[H]
\begin{center}
\includegraphics[width=15cm]{Images/graphe1.png}
\caption{Evolution du temps d'ex\'{e}cution du \og Branch \& Bound \fg{} en fonction de la taille du dictionnaire}
\end{center}
\end{figure}

On remarque bien que le temps d'ex\'{e}cution augmente exponentiellement en fonction de la taille du dictionnaire. En effet, le temps d'ex\'{e}cution d\'{e}pend du nombre de n\oe uds dans l'arbre et ce dernier est \'{e}gal \`{a} $\mathlarger{\sum_{i = 0}^{n} \prod_{j = 0}^{i} |D(x_j)|}$ avec $n$ le nombre de variables dans la grille et $D(x_i)$ le domaine de la variable $x_{i}$, $\forall i \in \{0, ..., n\}$.\\

\subsubsection*{En fonction de la taille de la grille}

Pour \'{e}tudier l'\'{e}volution du temps en fonction de la taille de la grille, nous avons g\'{e}n\'{e}r\'{e} 6 grilles de tailles $n \times n$, $\forall n \in \{4, ..., 9\}$ avec un dictionnaire contenant 850 mots.\\

\begin{figure}[H]
\begin{center}
\includegraphics[width=15cm]{Images/graphe2.png}
\caption{Evolution du temps d'ex\'{e}cution du \og Branch \& Bound \fg{} en fonction du nombre de variables dans la grille}
\end{center}
\end{figure}

Dans cette deuxi\`{e}me \'{e}tude, le temps d'ex\'{e}cution ne d\'{e}pend pas de la taille de la grille, mais du nombre de variables dans la grille. En effet, les grilles \`{a} 10 et 15 variables avait toutes les deux la m\^{e}me taille ($7 \times 7$) mais ont des temps d'\'{e}xecution assez diff\'{e}rents dans le cas o\`{u} les mots ne peuvent apparaitre qu'une seule fois dans la grille. Il d\'{e}pend \'{e}galement du dictionnaire utilis\'{e}. En effet, dans notre exemple, pour des grilles \`{a} 12 variables, le temps d'ex\'{e}cution est sup\'{e}rieure aux temps d'ex\'{e}cution des grilles \`{a} 18 et 15 variables.

De plus, il est int\'{e}ressant de noter que le temps d'ex\'{e}cution augmente plus rapidement en fonction de la taille du dictionnaire que du nombre de variable dans la grille.

\subsubsection*{Grille ANDROIDE}

Dans cette partie, nous avons constitu\'{e} un dictionnaire avec des mots-cl\'{e}s utilis\'{e}s fr\'{e}quemment dans les cours du master ANDROIDE, tous de poids 1, et des mots suppl\'{e}mentaires de poids inf\'{e}rieur \`{a} 1. Avec la grille C, on obtient la solution suivante:\\

Image

\bigskip

Le temps d'ex\'{e}cution \'{e}tant \'{e}gal \`{a} (temps).

\subsection{Bonus}
La section bonus a été réalisée. Les pages relatives aux UE du site web \url{androide.lip6.fr} ont été copiées dans un fichier texte. C'est ce texte qui a servi de référence pour la création du dictionnaire. Il y a beaucoup de mots, les fréquences sont donc très petites. Malheureusement, la taille de ce dictionnaire étant très grand, il est difficile de lancer l'algorithme de Branch And Bound qui prend beaucoup trop de temps. Le dictionnaire a alors été modifié manuellement pour correspondre aux besoins. Vous avez pu voir le résultat sur la figure précédente.

\newpage

\section*{Conclusion}
\addcontentsline{toc}{section}{Conclusion}


\newpage
\appendix
\section{Annexes}
\subsection{Exemples de Grilles vides et leur résolution}

\begin{figure}[H]
	\begin{center}
		\includegraphics{Images/gridA_empty.png}
		\includegraphics{Images/gridA_full.png}
		\caption{Grille A}
	\end{center}
\end{figure}

\begin{figure}[H]
	\begin{center}
		\includegraphics{Images/gridB_empty.png}
		\includegraphics{Images/gridB_full.png}
		\caption{Grille B}
	\end{center}
\end{figure}

\begin{figure}[H]
	\begin{center}
		\includegraphics{Images/random_grid5x5_empty.png}
		\includegraphics{Images/random_grid5x5_full.png}
		\caption{Grille randomGrid5x5 générée par nos soins}
	\end{center}
\end{figure}

\begin{figure}[H]
	\begin{center}
		\includegraphics{Images/gridC_empty.png}
		\includegraphics{Images/gridC_full.png}
		\caption{Grille C}
	\end{center}
\end{figure}

\begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.9]{Images/grid13x13_empty.png}
		\includegraphics[scale=0.9]{Images/grid13x13_full.png}
		\caption{Grille grid13x13GridIndex}
	\end{center}
\end{figure}



\end{document}